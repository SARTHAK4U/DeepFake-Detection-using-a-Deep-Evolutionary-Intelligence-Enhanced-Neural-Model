{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-09T14:39:28.565341Z","iopub.execute_input":"2023-03-09T14:39:28.565830Z","iopub.status.idle":"2023-03-09T14:39:33.644106Z","shell.execute_reply.started":"2023-03-09T14:39:28.565779Z","shell.execute_reply":"2023-03-09T14:39:33.642737Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:33.646898Z","iopub.execute_input":"2023-03-09T14:39:33.647448Z","iopub.status.idle":"2023-03-09T14:39:33.785775Z","shell.execute_reply.started":"2023-03-09T14:39:33.647410Z","shell.execute_reply":"2023-03-09T14:39:33.783971Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"class DeepFake(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.inception = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n        self.fc1 = nn.Linear(1000, 256)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p = 0.2)\n        self.fc2 = nn.Linear(256, 1)\n        \n    def forward(self, x : torch.Tensor):\n        output, aux = self.inception(x)\n        output = self.fc1(output)\n#         print('fc1 shape', output.shape)\n        output = self.relu(output)\n        output = self.dropout(output)\n        output = self.fc2(output)\n#         print('fc2 shape', output.shape)\n        output = torch.sigmoid(output)\n#         print('final shape', output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:33.789415Z","iopub.execute_input":"2023-03-09T14:39:33.790399Z","iopub.status.idle":"2023-03-09T14:39:33.809526Z","shell.execute_reply.started":"2023-03-09T14:39:33.790358Z","shell.execute_reply":"2023-03-09T14:39:33.808269Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\ndef def_val():\n  return 0\n\nouter_path = '/kaggle/input/celeb-df-ga/processed-dataset-ga/data/'\nall_labels = defaultdict(def_val)\nsubfolders = ['Celeb-real','Celeb-synthesis','YouTube-real']\nfor subfolder in subfolders:\n  for file in os.listdir('/kaggle/input/celeb-df-ga/processed-dataset-ga/data/' + subfolder):\n    if subfolder=='Celeb-real' or subfolder=='YouTube-real':\n      all_labels[outer_path + subfolder + '/' + file] = 0\n    else:\n      all_labels[outer_path + subfolder + '/' + file] = 1","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:33.813763Z","iopub.execute_input":"2023-03-09T14:39:33.814453Z","iopub.status.idle":"2023-03-09T14:39:33.967265Z","shell.execute_reply.started":"2023-03-09T14:39:33.814421Z","shell.execute_reply":"2023-03-09T14:39:33.966138Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"all_video_ids = []\nall_video_ids.extend(os.listdir('/kaggle/input/celeb-df-ga/processed-dataset-ga/data/Celeb-real'))\nall_video_ids.extend(os.listdir('/kaggle/input/celeb-df-ga/processed-dataset-ga/data/Celeb-synthesis'))\nall_video_ids.extend(os.listdir('/kaggle/input/celeb-df-ga/processed-dataset-ga/data/YouTube-real'))\n\ntest_df = pd.read_csv('/kaggle/input/test-files/test.txt', sep=' ', header=None, names=['label','video_id'])\n\ntest_video_ids = test_df['video_id']\ntest_video_ids = [outer_path + id[:-4] for id in test_video_ids]\n\ntrain_video_ids = list(set(all_video_ids).difference(set(test_video_ids)))\nprint(len(train_video_ids),len(test_video_ids),len(all_video_ids))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:33.969098Z","iopub.execute_input":"2023-03-09T14:39:33.969500Z","iopub.status.idle":"2023-03-09T14:39:34.010928Z","shell.execute_reply.started":"2023-03-09T14:39:33.969461Z","shell.execute_reply":"2023-03-09T14:39:34.009895Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1203 100 1203\n","output_type":"stream"}]},{"cell_type":"code","source":"train_video_ids = list(set(all_labels.keys()) - set(test_video_ids))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:34.012474Z","iopub.execute_input":"2023-03-09T14:39:34.013177Z","iopub.status.idle":"2023-03-09T14:39:34.018702Z","shell.execute_reply.started":"2023-03-09T14:39:34.013136Z","shell.execute_reply":"2023-03-09T14:39:34.017495Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"preprocess = transforms.Compose([\n    transforms.Resize(299),\n    transforms.CenterCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:34.020360Z","iopub.execute_input":"2023-03-09T14:39:34.021015Z","iopub.status.idle":"2023-03-09T14:39:34.030527Z","shell.execute_reply.started":"2023-03-09T14:39:34.020980Z","shell.execute_reply":"2023-03-09T14:39:34.029201Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train_paths = []\nfor video in train_video_ids:\n    frames = os.listdir(video)\n    X_train_paths.extend([str(video) + '/' + i for i in frames])\n    \ny_train = []\nfor frames in X_train_paths:\n    video_id = frames.split('/')\n    video_path = '/'.join(video_id[:-1])\n    y_train.append(all_labels[video_path])\n# y_train = y_train[:1000]\ny_train = torch.FloatTensor(y_train)\ny_train = y_train.unsqueeze(1)\n\n# X_train_paths = X_train_paths[:1000]\n\n\nX_test_lens = []\nX_test_paths = []\nfor video in test_video_ids:\n    frames = os.listdir(video)\n    X_test_lens.append(len(frames))\n    X_test_paths.extend([str(video) + '/' + i for i in frames])\n# X_test = []\n# for path in X_test_paths[:302]:\n#     input_image = Image.open(path)\n#     input_tensor = preprocess(input_image)\n#     X_test.append(input_tensor)\n# X_test = torch.stack(X_test)\n# print(X_test_lens)\n\ny_test = []\nfor frames in X_test_paths:\n    video_id = frames.split('/')\n    video_path = '/'.join(video_id[:-1])\n    y_test.append(all_labels[video_path])\ny_test = torch.FloatTensor(y_test)\ny_test = y_test.unsqueeze(1)\n\nprint(sum(X_test_lens[:10]))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:34.032290Z","iopub.execute_input":"2023-03-09T14:39:34.033157Z","iopub.status.idle":"2023-03-09T14:39:56.990521Z","shell.execute_reply.started":"2023-03-09T14:39:34.033119Z","shell.execute_reply":"2023-03-09T14:39:56.989324Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"250\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train = y_train.to(device)\n# X_test = X_test.to(device)\ny_test = y_test.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:39:56.992091Z","iopub.execute_input":"2023-03-09T14:39:56.993096Z","iopub.status.idle":"2023-03-09T14:40:01.107259Z","shell.execute_reply.started":"2023-03-09T14:39:56.993056Z","shell.execute_reply":"2023-03-09T14:40:01.106044Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class DFDataloader(Dataset):\n  \"\"\"\n  This is a custom dataset class. It can get more complex than this, but simplified so you can understand what's happening here without\n  getting bogged down by the preprocessing\n  \"\"\"\n  def __init__(self, X_train_paths, y):\n    self.y = y\n    self.X_train_paths = X_train_paths\n    if len(self.X_train_paths) != len(self.y):\n      print(len(self.X_train_paths), len(self.y))\n      raise Exception(\"The length of X does not match the length of Y\")\n\n  def __len__(self):\n    return len(self.y)\n\n  def __getitem__(self, index):\n    # note that this isn't randomly selecting. It's a simple get a single item that represents an x and y\n    input_image = Image.open(self.X_train_paths[index])\n    input_tensor = preprocess(input_image)\n    _x = input_tensor\n    _y = self.y[index]\n    return _x, _y","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:40:01.111075Z","iopub.execute_input":"2023-03-09T14:40:01.111459Z","iopub.status.idle":"2023-03-09T14:40:01.119595Z","shell.execute_reply.started":"2023-03-09T14:40:01.111420Z","shell.execute_reply":"2023-03-09T14:40:01.118542Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = DeepFake()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:40:01.121026Z","iopub.execute_input":"2023-03-09T14:40:01.123520Z","iopub.status.idle":"2023-03-09T14:40:04.473880Z","shell.execute_reply.started":"2023-03-09T14:40:01.123484Z","shell.execute_reply":"2023-03-09T14:40:04.472758Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/104M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d232b002ef7444e3b5b1fb5544d92436"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DeepFake(\n  (inception): Inception3(\n    (Conv2d_1a_3x3): BasicConv2d(\n      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (Conv2d_2a_3x3): BasicConv2d(\n      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (Conv2d_2b_3x3): BasicConv2d(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (Conv2d_3b_1x1): BasicConv2d(\n      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (Conv2d_4a_3x3): BasicConv2d(\n      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (Mixed_5b): InceptionA(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_1): BasicConv2d(\n        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_2): BasicConv2d(\n        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_5c): InceptionA(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_1): BasicConv2d(\n        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_2): BasicConv2d(\n        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_5d): InceptionA(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_1): BasicConv2d(\n        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch5x5_2): BasicConv2d(\n        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6a): InceptionB(\n      (branch3x3): BasicConv2d(\n        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3): BasicConv2d(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6b): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6c): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6d): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_6e): InceptionC(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7_3): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_3): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_4): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7dbl_5): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (AuxLogits): InceptionAux(\n      (conv0): BasicConv2d(\n        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (conv1): BasicConv2d(\n        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (fc): Linear(in_features=768, out_features=1000, bias=True)\n    )\n    (Mixed_7a): InceptionD(\n      (branch3x3_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2): BasicConv2d(\n        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_1): BasicConv2d(\n        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_3): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch7x7x3_4): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_7b): InceptionE(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_1): BasicConv2d(\n        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (Mixed_7c): InceptionE(\n      (branch1x1): BasicConv2d(\n        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_1): BasicConv2d(\n        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3_2b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_1): BasicConv2d(\n        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_2): BasicConv2d(\n        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3a): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch3x3dbl_3b): BasicConv2d(\n        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (branch_pool): BasicConv2d(\n        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (dropout): Dropout(p=0.5, inplace=False)\n    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  )\n  (fc1): Linear(in_features=1000, out_features=256, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc2): Linear(in_features=256, out_features=1, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"torch.sum(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:40:04.475445Z","iopub.execute_input":"2023-03-09T14:40:04.476087Z","iopub.status.idle":"2023-03-09T14:40:04.568537Z","shell.execute_reply.started":"2023-03-09T14:40:04.476047Z","shell.execute_reply":"2023-03-09T14:40:04.566917Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor(1550., device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"to_train = ['fc2.bias', 'fc2.weight', 'fc1.bias', 'fc1.weight']\nfor name, param in model.named_parameters():\n    param.requires_grad = True if name in to_train else False","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:40:04.569806Z","iopub.execute_input":"2023-03-09T14:40:04.570147Z","iopub.status.idle":"2023-03-09T14:40:04.577669Z","shell.execute_reply.started":"2023-03-09T14:40:04.570112Z","shell.execute_reply":"2023-03-09T14:40:04.576395Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n\nepochs = 30\nfor epoch in range(epochs):\n    model.train()\n    losses = []\n    train_dataloader = iter(DataLoader(DFDataloader(X_train_paths, y_train), batch_size=256, shuffle=True))    \n    for X_train_dl, y_train_dl in tqdm(train_dataloader):\n        X_train_dl = X_train_dl.to(device)\n        y_train_dl = y_train_dl.to(device)\n        y_pred = model(X_train_dl)\n        loss = loss_fn(y_pred, y_train_dl)\n        losses.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    avg_loss = sum(losses)/len(losses)\n    print('Avg Loss: ', avg_loss)\n    \n    calculated_mean_scores = []\n    actual_scores = []\n    with torch.no_grad():\n        test_dataloader = iter(DataLoader(DFDataloader(X_test_paths, y_test), batch_size=25, shuffle=False))\n        for X_test_dl, y_test_dl in test_dataloader:\n            X_test_dl = X_test_dl.to(device)\n            y_test_dl = y_test_dl.to(device)\n            y_pred_test = model(X_test_dl)\n#             print(y_test_dl)\n            loss_test = loss_fn(y_pred_test, y_test_dl)\n            video_pred_scores = y_pred_test.squeeze(1)\n            calculated_mean_scores.append(torch.mean(video_pred_scores).item())\n            actual_scores.append(y_test_dl[0].squeeze().item())\n#         print(calculated_mean_scores)\n#         print(actual_scores)\n        calculated_mean_scores = [1 if score>=0.5 else 0 for score in calculated_mean_scores]\n        acc = torch.sum(torch.eq(torch.FloatTensor(calculated_mean_scores),torch.FloatTensor(actual_scores))).item()/len(actual_scores)\n        print('accuracy:', acc)\n        scheduler.step(acc)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T14:40:04.579530Z","iopub.execute_input":"2023-03-09T14:40:04.580276Z","iopub.status.idle":"2023-03-09T14:48:17.053402Z","shell.execute_reply.started":"2023-03-09T14:40:04.580239Z","shell.execute_reply":"2023-03-09T14:48:17.049894Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f21030958c3465abb5ee15ec1510a29"}},"metadata":{}},{"name":"stdout","text":"Avg Loss:  0.5585768962347949\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1676033320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDFDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX_test_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_dl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mX_test_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0my_test_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/103734500.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# note that this isn't randomly selecting. It's a simple get a single item that represents an x and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3131\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3132\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}